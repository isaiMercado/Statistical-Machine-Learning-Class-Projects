{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random \n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "from scipy.stats import dirichlet\n",
    "#from numpy.random import dirichlet \n",
    "from numpy.random import multinomial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I_iterations = 100#0\n",
    "K_topics = 10 \n",
    "M_documents = 472 \n",
    "V_vocabulary = 0\n",
    "\n",
    "\n",
    "# This variables just help to give meaning to indexes but they are\n",
    "# not used in the algorithm\n",
    "topics = list()\n",
    "documents = list()\n",
    "vocabulary = list()\n",
    "\n",
    "\n",
    "documents_vocabulary_count = None\n",
    "documents_vocabulary_topic = None\n",
    "documents_topic = None\n",
    "\n",
    "\n",
    "A_prior_topic_per_document = None\n",
    "B_words_per_document_prior = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vocabulary = set()\n",
    "documents_counts = list() \n",
    "for document_index in range(1, M_documents + 1):\n",
    "    document_string = open('files/output%04d.txt' % document_index).read() \n",
    "    words = re.sub('[^a-z ]+', ' ', document_string.lower()).split()\n",
    "    word_count = dict()\n",
    "    for word in words:\n",
    "        vocabulary.add(word)\n",
    "        if word in word_count:\n",
    "            word_count[word] = word_count[word] + 1\n",
    "        else:\n",
    "            word_count[word] = 0\n",
    "    documents_counts.append(word_count)\n",
    "\n",
    "    \n",
    "vocabulary = list(vocabulary)\n",
    "V_vocabulary = len(vocabulary)\n",
    "\n",
    "documents_vocabulary_count = np.zeros((M_documents, V_vocabulary)) #[[0 for w in range(V_vocabulary)] for d in range(M_documents)] #np.zeros((M_documents, V_vocabulary, K_topics))\n",
    "documents_vocabulary_topic = np.zeros((M_documents, V_vocabulary)) #[[0 for w in range(V_vocabulary)] for d in range(M_documents)] # np.zeros((M_documents, V_vocabulary))\n",
    "documents_topic = np.zeros((M_documents)) #[0 for d in range(M_documents)] # np.zeros((M_documents))\n",
    "\n",
    "A_prior_topic_per_document = np.ones((K_topics))\n",
    "B_words_per_document_prior = np.ones((V_vocabulary))\n",
    "\n",
    "#print(\"documents_counts\\n\" + str(documents_counts))\n",
    "#print(\"documents_counts[0]\\n\" + str(documents_counts[0]))\n",
    "\n",
    "for d in range(M_documents):\n",
    "    random_topic = random.randint(0, K_topics - 1)\n",
    "    documents_topic[d] = random_topic\n",
    "    for w in range(V_vocabulary):\n",
    "        random_topic = random.randint(0, K_topics - 1)\n",
    "        if vocabulary[w] in documents_counts[d]:\n",
    "            documents_vocabulary_topic[d][w] = random_topic\n",
    "            documents_vocabulary_count[d][w] = documents_counts[d][vocabulary[w]]\n",
    "            \n",
    "#print(\"documents_vocabulary_topics_count\\n\" + str(documents_vocabulary_topics_count))\n",
    "#print(\"documents_vocabulary_topic\\n\" + str(documents_vocabulary_topic))\n",
    "#print(\"documents_topic\\n\" + str(documents_topic))\n",
    "\n",
    "#print(\"documents_vocabulary_topics_count[0][0]\\n\" + str(documents_vocabulary_topics_count[7][0]))\n",
    "#print(\"documents_vocabulary_topic[0]\\n\" + str(documents_vocabulary_topic[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_best_word_topic(words_counts_per_document):\n",
    "#     best_topic = None\n",
    "#     best_topic_prob = 0.0\n",
    "#     theta_distribution = dirichlet.pdf(B_words_per_document_prior, alpha = B_words_per_document_prior + words_counts_per_document) \n",
    "#     print(theta_distribution)\n",
    "#     for k in range(K_topics):\n",
    "#         topic_prob = theta_distribution.pdf(k)\n",
    "#         if best_topic_prob < topic_prob:\n",
    "#             best_topic_prob = topic_prob\n",
    "#             best_topic = k\n",
    "#     return best_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_best_document_topic(words_counts_per_document):\n",
    "#     best_topic = multinomial(words_counts_per_document)\n",
    "#     return best_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-d1646997b863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocuments_vocabulary_topic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_topics_counts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mword_topics_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_topics_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdocuments_vocabulary_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "KEY = 0\n",
    "\n",
    "for i in range(I_iterations):\n",
    "    \n",
    "    for w in range(V_vocabulary):\n",
    "#         document_topics_counts = dict()\n",
    "        word_topics_counts = dict()\n",
    "        for d in range(M_documents):\n",
    "            t = documents_vocabulary_topic[d][w]\n",
    "            if t in word_topics_counts:\n",
    "                word_topics_counts[t] = word_topics_counts[t] + documents_vocabulary_count[d][w]\n",
    "            else:\n",
    "                word_topics_counts[t] = 0\n",
    "                \n",
    "#             if t in document_topics_counts:\n",
    "#                 document_topics_counts[t] = document_topics_counts[t] + documents_vocabulary_count.transpose()[w][d]\n",
    "#             else:\n",
    "#                 document_topics_counts[t] = 0\n",
    "                \n",
    "        #print(\"before documents_vocabulary_topic \" + str(documents_vocabulary_topic[d]))\n",
    "        word_topics_counts = sorted(word_topics_counts.items(), key=operator.itemgetter(1))\n",
    "        #print(\"word_topics_counts \" + str(word_topics_counts))\n",
    "        best_word_topic = word_topics_counts[len(word_topics_counts) - 1]\n",
    "        #print(\"best_word_topic \" + str(best_word_topic))\n",
    "        documents_vocabulary_topic[d][w] = best_word_topic[KEY]\n",
    "        #print(\"after documents_vocabulary_topic \" + str(documents_vocabulary_topic[d]))\n",
    "        \n",
    "        #print(\"\\nbefore documents_topic \" + str(documents_topic))\n",
    "        #document_topics_counts = sorted(document_topics_counts.items(), key=operator.itemgetter(1))\n",
    "        #print(\"document_topics_counts \" + str(document_topics_counts))\n",
    "        #best_document_topic = document_topics_counts[len(document_topics_counts) - 1]\n",
    "        #print(\"best_document_topic \" + str(best_document_topic))\n",
    "        #documents_topic[d] = best_document_topic[KEY]\n",
    "        #print(\"after documents_topic \" + str(documents_topic) + \"\\n\\n\")\n",
    "            \n",
    "#             t = documents_vocabulary_topic[d][w]\n",
    "#             if t in document_topics_counts:\n",
    "#                 document_topics_counts[t] = document_topics_counts[t] + documents_vocabulary_count[d][w]\n",
    "#             else:\n",
    "#                 document_topics_counts[t] = 0\n",
    "#         document_topics_counts = sorted(document_topics_counts.items(), key=operator.itemgetter(1))\n",
    "#         best_topic = document_topics_counts[len(document_topics_counts) - 1]\n",
    "#         documents_topic[d] = best_topic[KEY]\n",
    "        #print(\"doc topics\" + str(documents_topic))\n",
    "\n",
    "    for d in range(M_documents):\n",
    "        document_topics_counts = dict()\n",
    "        for w in range(V_vocabulary):\n",
    "            t = documents_vocabulary_topic[d][w]\n",
    "            if t in document_topics_counts:\n",
    "                document_topics_counts[t] = document_topics_counts[t] + documents_vocabulary_count[d][w]\n",
    "            else:\n",
    "                document_topics_counts[t] = 0\n",
    "        document_topics_counts = sorted(document_topics_counts.items(), key=operator.itemgetter(1))\n",
    "        best_topic = document_topics_counts[len(document_topics_counts) - 1]\n",
    "        documents_topic[d] = best_topic[KEY]\n",
    "        #print(\"doc topics\" + str(documents_topic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\nafter documents_topic \" + str(documents_topic))\n",
    "\n",
    "counter = 0\n",
    "for t in range(K_topics):\n",
    "    print(\"\\n\\nTOPIC \" + str(t) + \"\\n\")\n",
    "    for d in range(M_documents):\n",
    "        for w in range(V_vocabulary):\n",
    "            if counter < 25:\n",
    "                if documents_vocabulary_count[d][w] > 0 and documents_vocabulary_topic[d][w] == t:\n",
    "                    print(vocabulary[w])\n",
    "                    counter = counter + 1\n",
    "            \n",
    "    counter = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib tk\n",
    "%matplotlib inline\n",
    "\n",
    "xRange = range(M_documents)\n",
    "#labels = [str(d) for d in xRange]\n",
    "figure = plt.figure(figsize=(35,30))\n",
    "subplot = figure.add_subplot(111)\n",
    "matplot = subplot.matshow(np.atleast_2d(documents_topic))\n",
    "#figure.colorbar(matplot)\n",
    "subplot.set_title(\"Documents' Topics\\n\\n\")\n",
    "#subplot.set_xticklabels(labels)\n",
    "#subplot.set_yticklabels([\"\"])\n",
    "#subplot.set_xticks(xRange)\n",
    "#subplot.set_yticks(xRange)\n",
    "subplot.set_xlabel(\"Documents\")\n",
    "#subplot.set_ylabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "plt.savefig('matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
